%% the-core.tex  
% цей розділ присвячений детальному огляду теорії, методів та алгоритмів
\chapter{Методи та алгортми\ldots}\label{ch:02}

Одні з перших засадничих робіт, присвячених процесам самоорганізації, належать Розенблату~\cite{Ros1963}, у яких висвітлено головні ідеї, сформульовані для математичних моделей штучних нейронних мереж. Запропоновані підходи не дали практичного результату, але заклали підґрунтя для  подальших досліджень~\cite{ShlHlav2004}. В Україні дослідження моделювання систем на основі процесів самоорганізації представлене науковою школою О.Г. Івахненка, яким було суттєво розвинене вчення про індуктивне моделювання~\cite{Iva1982}. Напрацювання школи Івахненка набули міжнародного визнання~\cite{MaIv1994}.

\section{Перший підрозділ}\label{ch:0201}

Із досліджень у нейробіології відомо, що різні частини кори головного мозку організовані у відповідності до різних видів чуття~\cite{Koh2001}. Деякі новітні дослідження людського мозку вказують на те, що сигнали-реакції формуються на корі головного мозку в тому самому топологічному порядку, в якому вони були отримані органами чуття (наприклад, очима). Карти Кохонена слідують тому самому принципу, будуючи відображення вхідного простору на ґратку своїх елементів у топологічно впорядкований спосіб. Такий зв'язок із способом функціонування головного мозку зумовив класифікацію карт Кохонена як окремої архітектури штучних нейронних мереж~\cite{RMS1992}. Тому карту Кохонена також називають \emph{нейромережею Кохонена}, а її елементи -- \emph{нейронами}.

\subsection{Перший підрозділ першого підрозділу}

\begin{table}
   \centering
   \caption{Приклад балиці}
   \label{tbl:medical-data-fragment}
   \def~{\phantom{0}}
   \def\ExSp#1{\noalign{\vskip #1}}
   \def\Hline{\noalign{\hrule height 2\arrayrulewidth}}
   \begin{tabular}{cccccccccccccccc}
     \ExSp{0.2ex} \Hline \ExSp{1ex}
     \rotatebox{45}{\tiny AGE} & \rotatebox{45}{\tiny G} & \rotatebox{45}{\tiny PIK} & \rotatebox{45}{\tiny KHK\_AKMK} & \rotatebox{45}{\tiny KV} & \rotatebox{45}{\tiny SK} & \rotatebox{45}{\tiny UA} & \rotatebox{45}{\tiny AA} & \rotatebox{45}{\tiny BE} & \rotatebox{45}{\tiny OH} & \rotatebox{45}{\tiny REW} & \rotatebox{45}{\tiny R\_AK} & \rotatebox{45}{\tiny R\_MK} & \rotatebox{45}{\tiny R\_AKMK} & \rotatebox{45}{\tiny GH} & \rotatebox{45}{\tiny KHKS}\\
     \ExSp{0.2ex} \hline\ExSp{1ex}
     0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & \cellcolor[gray]{0.9}1\\
     1 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 1 & 0 & \cellcolor[gray]{0.9}0\\
     1 & 0 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & \cellcolor[gray]{0.9}1\\
     1 & 1 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & \cellcolor[gray]{0.9}1\\
     \ExSp{1ex} \hline
   \end{tabular}
\end{table}

\begin{table}
  \centering
  \caption{Приклад ще однієї таблиці}
  \label{tbl:medical-data-stats}        
  \def~{\phantom{0}}
  \def\exsp#1{\noalign{\vskip #1}}
  \def\hline{\noalign{\hrule height 2\arrayrulewidth}}
  \begin{tabular}{ccccc}
  \exsp{0.2ex} \hline \exsp{1ex}
  \rotatebox{45}{\smallК-сть хворих} & \rotatebox{45}{\smallВідсоток хворих} & \rotatebox{45}{\smallК-сть здорових} & \rotatebox{45}{\smallВідсоток здорових} & \rotatebox{45}{\smallЗагальна к-сть}\\
  \exsp{0.2ex} \hline\exsp{1ex}
  756 & 21.6\% & 2744 & 78.4\% & 3500\\
  \exsp{1ex} \hline
  \end{tabular}
\end{table}

\subsection{Другий підрозділ першого підрозділу}

\begin{algorithm}[!htb]
\caption{Приклад вербальної форми опису алгоритму.}\label{alg:classifier}
\begin{enumerate}
\item[ ]\emph{Ініціалізація.} Запровадимо пару змінних $(a_i,b_i)$ для кожного елемента $m_i\in M$, які міститимуть кількість реагувань елемента на хворих та здорових пацієнтів. Присвоюємо $a_i\leftarrow 0$, $b_i\leftarrow 0$, $i=\overline{1,|M|}$. Вибираємо множину вхідних даних, для якої обчислюватиметься успішність класифікації, яку позначимо $T$. Уводимо множину елементів-переможців $K\leftarrow\varnothing$.
\item[1.] Вибираємо вхідний вектор $x\in T$ і вилучаємо його, покладаючи $T\leftarrow T\setminus\{x\}$.
\item[2.] Для вектора $x$ визначаємо переможця $m(x)$ відповідно до співвідношення~(\ref{eq:winner}); покладаємо $K\leftarrow K\cup\{m(x)\}$.
\item[3.] Якщо вектору $x$ відповідає ознака прийняття рішень зі значення 1 (хворі пацієнти), то покладаємо $a_{m(x)}\leftarrow a_{m(x)} + 1$, інакше -- $b_{m(x)}\leftarrow b_{m(x)} + 1$.
\item[4.] Якщо $T\neq \varnothing$, то повертаємось на крок 1.
\item[5.] Обчислимо успішність кожного елемента $m\in K$:\\$s_k=\dfrac{\xi_k}{a_k + b_k}*100$, $k\in I(K)$, де $I(K)$ -- множина індексів елементів-переможців, $\xi_k=\left\{\begin{array}{r@{,\quad}l}a_k & a_k\geq b_k \\ b_k & a_k < b_k\end{array}\right.$
\item[6.] Обчислюємо загальну успішність класифікації: \begin{eqnarray*}S=\dfrac{1}{|K|}\sum_{k=I(K)}s_k,\end{eqnarray*} де $|K|$ -- кількість елементів-переможців для векторів множини $T$.
\end{enumerate}
\end{algorithm}

\section{Висновки до розділу~\ref{ch:02}}
У цьому розділі наведено результати дослідження\ldots